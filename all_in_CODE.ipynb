{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3be16c-9fe3-43e8-989d-d5b5a378ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all code in one file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d99a468c-fd82-4693-ad2e-8a3b0c6a032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "# # read .mat file \n",
    "# mat = scipy.io.loadmat('Prostate_Tumor.mat')\n",
    "# mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f3160e3-72fc-43f4-9fa0-283390d7640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read csv file \n",
    "# data = pd.read_csv('heart.csv')\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c153fda-1130-4040-aab9-fdd3cef7fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read .dat file \n",
    "# import pandas as pd\n",
    "\n",
    "# # Specify the delimiter if needed (e.g., ',' for CSV or '\\t' for tab)\n",
    "# data = pd.read_csv('Sonar.dat', delimiter=',')  # Adjust delimiter\n",
    "# # print(data)\n",
    "\n",
    "# # convert into dataFrame \n",
    "# df = pd.DataFrame(data)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01e1f5-5d3d-4425-919c-f3a638c876b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb64d819-1316-4b24-ae76-103d612fe7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the PCA and decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09a65e01-37e6-4b2e-a05a-6b63713501d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN, Created on: Mon Jun 23 13:56:18 2003',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'data': array([[  1. ,   6.1,  -0.1, ...,  14. ,  19.3,  37.3],\n",
       "        [  1. ,   1. ,   0. , ...,   6. ,   6. ,  26. ],\n",
       "        [  1. ,  22. ,   2. , ..., -13. , -10. , -21. ],\n",
       "        ...,\n",
       "        [  0. ,  -4. ,   1. , ...,   1. ,   2. ,  24. ],\n",
       "        [  0. ,   0. ,   0. , ...,   5. ,  -6. ,  25. ],\n",
       "        [  0. ,   4. ,   0. , ...,   9. ,   3. ,  21. ]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prostate_Tumor = scipy.io.loadmat('Prostate_Tumor.mat')\n",
    "Prostate_Tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a59db0c6-0a97-4d17-b846-0441a64953bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>10500</th>\n",
       "      <th>10501</th>\n",
       "      <th>10502</th>\n",
       "      <th>10503</th>\n",
       "      <th>10504</th>\n",
       "      <th>10505</th>\n",
       "      <th>10506</th>\n",
       "      <th>10507</th>\n",
       "      <th>10508</th>\n",
       "      <th>10509</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>11.9</td>\n",
       "      <td>14.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-15.1</td>\n",
       "      <td>12.7</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>72.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>37.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1656.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2554.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5676.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1519.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3355.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>4767.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1671.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 10510 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1      2      3      4      5      6      7       8      9      \\\n",
       "0      1.0    6.1   -0.1   11.9   14.4    6.0  -15.1   12.7  1731.0    3.1   \n",
       "1      1.0    1.0    0.0    2.0    4.0    0.0    0.0    6.0  1656.0    1.0   \n",
       "2      1.0   22.0    2.0   51.0   52.0   25.0  -20.0   70.0  3600.0   15.0   \n",
       "3      1.0   14.0    6.0   15.0   21.0   11.0  -17.0   38.0  2554.0   12.0   \n",
       "4      1.0   13.0    4.0   39.0   25.0   12.0  -17.0   36.0  5676.0   17.0   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...     ...    ...   \n",
       "97     0.0    3.0    0.0    3.0    4.0   -2.0    0.0   10.0  1519.0   -1.0   \n",
       "98     0.0   -2.0    0.0    6.0   13.0    0.0   -1.0   13.0  3355.0    4.0   \n",
       "99     0.0   -4.0    1.0    4.0    5.0    0.0   -4.0   -4.0  4767.0    1.0   \n",
       "100    0.0    0.0    0.0    2.0    4.0    1.0   -3.0    8.0  1671.0    2.0   \n",
       "101    0.0    4.0    0.0    4.0    8.0    0.0    0.0    7.0  2084.0    0.0   \n",
       "\n",
       "     ...  10500  10501  10502  10503  10504  10505  10506  10507  10508  10509  \n",
       "0    ...   12.3   72.8    4.1    2.5    5.0   22.5    7.3   14.0   19.3   37.3  \n",
       "1    ...    7.0   25.0   10.0    2.0    4.0    5.0    1.0    6.0    6.0   26.0  \n",
       "2    ...   25.0  111.0  -66.0   12.0   14.0   59.0   16.0  -13.0  -10.0  -21.0  \n",
       "3    ...   14.0  129.0  -14.0    0.0   23.0   35.0    5.0   25.0  -27.0    0.0  \n",
       "4    ...   21.0   94.0  -41.0   16.0   18.0   49.0   29.0   32.0   30.0  -13.0  \n",
       "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "97   ...   19.0   42.0   15.0   -3.0   38.0    5.0    0.0   -2.0    4.0   24.0  \n",
       "98   ...   15.0   31.0    3.0   -2.0    1.0    5.0    0.0    6.0   -3.0   20.0  \n",
       "99   ...   19.0   32.0    9.0    0.0    0.0    0.0   -1.0    1.0    2.0   24.0  \n",
       "100  ...    9.0   26.0   11.0    1.0    6.0    3.0    0.0    5.0   -6.0   25.0  \n",
       "101  ...   10.0   24.0   -2.0    1.0   14.0    5.0    1.0    9.0    3.0   21.0  \n",
       "\n",
       "[102 rows x 10510 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prostate_Tumor_df = pd.DataFrame(Prostate_Tumor['data'])\n",
    "Prostate_Tumor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6ae7c50-071c-4b1e-899f-739e41006a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> X: (102, 10509), y: (102,)\n",
      "0\n",
      "0.0    52\n",
      "1.0    50\n",
      "Name: count, dtype: int64\n",
      "Train/Test Shapes -> X_train: (91, 10509), X_test: (11, 10509), y_train: (91,), y_test: (11,)\n",
      "Train/Test Shapes -> X_train: (81, 10509), X_test: (21, 10509), y_train: (81,), y_test: (21,)\n",
      "Train/Test Shapes -> X_train: (71, 10509), X_test: (31, 10509), y_train: (71,), y_test: (31,)\n",
      "Train/Test Shapes -> X_train: (61, 10509), X_test: (41, 10509), y_train: (61,), y_test: (41,)\n",
      "Results for Test Sizes PCA + Decision Tree: {0.1: 0.7272727272727273, 0.2: 0.6666666666666666, 0.3: 0.7741935483870968, 0.4: 0.8536585365853658}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "X = Prostate_Tumor_df.iloc[:, 1:]  # All columns except the first (features)\n",
    "y = Prostate_Tumor_df.iloc[:, 0]   # First column (labels)\n",
    "print(f\"Shapes -> X: {X.shape}, y: {y.shape}\")\n",
    "# print(Prostate_Tumor_df[0].value_counts()) # no. of classes\n",
    "# Ensure X and y are valid for ML\n",
    "if len(X.shape) == 1:\n",
    "    X = X.values.reshape(-1, 1)  # Convert 1D to 2D\n",
    "\n",
    "if len(y.shape) == 1:\n",
    "    y = y.values  # Ensure y is a 1D array\n",
    "\n",
    "# Test size variations\n",
    "test_sizes = [0.1, 0.2, 0.3, 0.4]\n",
    "pca_components = 50\n",
    "results_test_size = {}\n",
    "\n",
    "# Loop over different test sizes\n",
    "for test_size in test_sizes:\n",
    "    # Split data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    print(f\"Train/Test Shapes -> X_train: {X_train.shape}, X_test: {X_test.shape}, y_train: {y_train.shape}, y_test: {y_test.shape}\")\n",
    "    \n",
    "    # Ensure X_train and X_test are 2D arrays\n",
    "    assert len(X_train.shape) == 2, \"X_train should be 2D.\"\n",
    "    assert len(X_test.shape) == 2, \"X_test should be 2D.\"\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=min(pca_components, X_train.shape[1]))  # Ensure n_components doesn't exceed features\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    # print(\"X_train_pca\", X_train_pca)\n",
    "    # print(\"X_test_pca\", X_test_pca)\n",
    "    # Train a Decision Tree\n",
    "    clf = DecisionTreeClassifier( criterion='gini', splitter='best', max_depth=10, min_samples_split=3, min_samples_leaf=1, max_features=None,random_state=42)\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results_test_size[test_size] = accuracy\n",
    "\n",
    "print(\"Results for Test Sizes PCA + Decision Tree:\", results_test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4690f225-d218-4287-bfea-47eaa416bf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_5, std_5: \n",
      " 0.7546666666666667 0.10680471509035958\n",
      "mean_10, std_10: \n",
      " 0.7969090909090909 0.10562853984483583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Function to perform k-fold cross-validation and repeat it n times\n",
    "def cross_validation_repeat(X, y, k_folds, n_repeats, pca_components):\n",
    "    accuracies = []\n",
    "\n",
    "    for _ in range(n_repeats):\n",
    "        # Apply PCA\n",
    "        pca = PCA(n_components=pca_components)\n",
    "        X_pca = pca.fit_transform(X)\n",
    "\n",
    "        # Perform k-fold cross-validation\n",
    "        kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "        clf = DecisionTreeClassifier(random_state=42)\n",
    "        fold_accuracies = cross_val_score(clf, X_pca, y, cv=kf, scoring='accuracy')\n",
    "        accuracies.extend(fold_accuracies)\n",
    "        # print(\"accuracies\\n\",accuracies)\n",
    "    # Calculate mean and standard deviation\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "    return mean_accuracy, std_accuracy\n",
    "\n",
    "# Perform 5-fold cross-validation repeated 10 times\n",
    "mean_5, std_5 = cross_validation_repeat(X, y, k_folds=5, n_repeats=10, pca_components=pca_components)\n",
    "\n",
    "# Perform 10-fold cross-validation repeated 10 times\n",
    "mean_10, std_10 = cross_validation_repeat(X, y, k_folds=10, n_repeats=10, pca_components=pca_components)\n",
    "\n",
    "print (\"mean_5, std_5: \\n\",mean_5, std_5)\n",
    "print (\"mean_10, std_10: \\n\", mean_10, std_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1527f5e2-3437-4a38-9123-d0f33f7d53d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57bc7539-f3a9-4698-a32b-56d06b93b414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> X: (102, 10509), y: (102,)\n",
      "Train/Test Shapes -> X_train: (91, 10509), X_test: (11, 10509), y_train: (91,), y_test: (11,)\n",
      "Train/Test Shapes -> X_train: (81, 10509), X_test: (21, 10509), y_train: (81,), y_test: (21,)\n",
      "Train/Test Shapes -> X_train: (71, 10509), X_test: (31, 10509), y_train: (71,), y_test: (31,)\n",
      "Train/Test Shapes -> X_train: (61, 10509), X_test: (41, 10509), y_train: (61,), y_test: (41,)\n",
      "Results for Test Sizes with LDA + Decision Tree: {0.1: 0.6363636363636364, 0.2: 0.8095238095238095, 0.3: 0.6774193548387096, 0.4: 0.8292682926829268}\n"
     ]
    }
   ],
   "source": [
    "# LDA + Decision tree \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "X = Prostate_Tumor_df.iloc[:, 1:]  # All columns except the first (features)\n",
    "y = Prostate_Tumor_df.iloc[:, 0]   # First column (labels)\n",
    "print(f\"Shapes -> X: {X.shape}, y: {y.shape}\")\n",
    "\n",
    "# Ensure X and y are valid for ML\n",
    "if len(X.shape) == 1:\n",
    "    X = X.values.reshape(-1, 1)  # Convert 1D to 2D\n",
    "\n",
    "if len(y.shape) == 1:\n",
    "    y = y.values  # Ensure y is a 1D array\n",
    "\n",
    "# Test size variations\n",
    "test_sizes = [0.1, 0.2, 0.3, 0.4]\n",
    "lda_components = 1  # You can limit the number of components for LDA if necessary\n",
    "results_test_size = {}\n",
    "\n",
    "# Loop over different test sizes\n",
    "for test_size in test_sizes:\n",
    "    # Split data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    print(f\"Train/Test Shapes -> X_train: {X_train.shape}, X_test: {X_test.shape}, y_train: {y_train.shape}, y_test: {y_test.shape}\")\n",
    "    \n",
    "    # Ensure X_train and X_test are 2D arrays\n",
    "    assert len(X_train.shape) == 2, \"X_train should be 2D.\"\n",
    "    assert len(X_test.shape) == 2, \"X_test should be 2D.\"\n",
    "    \n",
    "    # Apply LDA\n",
    "    lda = LDA(n_components=min(lda_components, X_train.shape[1]-1))  # LDA components cannot exceed (n_features - 1)\n",
    "    X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "    X_test_lda = lda.transform(X_test)\n",
    "    \n",
    "    # Train a Decision Tree\n",
    "    clf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=10, min_samples_split=3, min_samples_leaf=1, random_state=42)\n",
    "    clf.fit(X_train_lda, y_train)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = clf.predict(X_test_lda)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results_test_size[test_size] = accuracy\n",
    "\n",
    "print(\"Results for Test Sizes with LDA + Decision Tree:\", results_test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba258eb5-f464-4028-ba82-bfc274c43805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA + Decision Tree Results:\n",
      "mean_5_LDA, std_5_LDA: \n",
      " 0.8514285714285714 0.07207013464945115\n",
      "mean_10_LDA, std_10_LDA: \n",
      " 0.8518181818181819 0.12122310556290021\n"
     ]
    }
   ],
   "source": [
    "# applying 5-fold and 10-fold 10 times \n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Function to perform k-fold cross-validation and repeat it n times using LDA + Decision Tree\n",
    "def cross_validation_repeat_LDA(X, y, k_folds, n_repeats, lda_components):\n",
    "    accuracies = []\n",
    "\n",
    "    for _ in range(n_repeats):\n",
    "        # Apply LDA\n",
    "        lda = LDA(n_components=min(lda_components, X.shape[1] - 1))  # Ensure n_components does not exceed (n_features - 1)\n",
    "        X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "        # Perform k-fold cross-validation\n",
    "        kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "        clf = DecisionTreeClassifier(random_state=42)\n",
    "        fold_accuracies = cross_val_score(clf, X_lda, y, cv=kf, scoring='accuracy')\n",
    "        accuracies.extend(fold_accuracies)\n",
    "    \n",
    "    # Calculate mean and standard deviation\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "    return mean_accuracy, std_accuracy\n",
    "\n",
    "# Perform 5-fold cross-validation repeated 10 times using LDA\n",
    "mean_5_LDA, std_5_LDA = cross_validation_repeat_LDA(X, y, k_folds=5, n_repeats=10, lda_components=1)\n",
    "\n",
    "# Perform 10-fold cross-validation repeated 10 times using LDA\n",
    "mean_10_LDA, std_10_LDA = cross_validation_repeat_LDA(X, y, k_folds=10, n_repeats=10, lda_components=1)\n",
    "\n",
    "print(\"LDA + Decision Tree Results:\")\n",
    "print(\"mean_5_LDA, std_5_LDA: \\n\", mean_5_LDA, std_5_LDA)\n",
    "print(\"mean_10_LDA, std_10_LDA: \\n\", mean_10_LDA, std_10_LDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7446eac0-28d1-45e3-aef8-0ea540cec891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Ravi\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 163ms/step - accuracy: 0.9033 - loss: 0.2987 - val_accuracy: 0.9697 - val_loss: 0.1170\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 141ms/step - accuracy: 0.9754 - loss: 0.0828 - val_accuracy: 0.9784 - val_loss: 0.0908\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 118ms/step - accuracy: 0.9803 - loss: 0.0719 - val_accuracy: 0.9759 - val_loss: 0.0866\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 139ms/step - accuracy: 0.9812 - loss: 0.0708 - val_accuracy: 0.9730 - val_loss: 0.1186\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 88ms/step - accuracy: 0.9823 - loss: 0.0653 - val_accuracy: 0.9772 - val_loss: 0.0985\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9776 - loss: 0.0924\n",
      "Test Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# CNN on MNIST dataset in image form \n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Paths to training and testing datasets\n",
    "train_dir = r\"D:\\dataset for ML\\MNIST Dataset JPG format\\MNIST - JPG - training\"\n",
    "test_dir = r\"D:\\dataset for ML\\MNIST Dataset JPG format\\MNIST - JPG - testing\"\n",
    "\n",
    "# Data preprocessing\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Load training and testing datasets without resizing\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(28, 28),  # Already 28x28, just to confirm\n",
    "    color_mode=\"grayscale\",  # MNIST images are grayscale\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\"  # One-hot encoding for labels\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(28, 28),  # Already 28x28\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # 10 classes for digits 0-9\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=5,\n",
    "    validation_data=test_data\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b641806b-fb76-41e9-be76-e5ac20c163e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b3fb723-30f6-4552-8b1b-fb44bd3fb72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> X: (102, 10509), y: (102,)\n",
      "Train/Test Shapes -> X_train: (91, 10509), X_test: (11, 10509), y_train: (91,), y_test: (11,)\n",
      "Train/Test Shapes -> X_train: (81, 10509), X_test: (21, 10509), y_train: (81,), y_test: (21,)\n",
      "Train/Test Shapes -> X_train: (71, 10509), X_test: (31, 10509), y_train: (71,), y_test: (31,)\n",
      "Train/Test Shapes -> X_train: (61, 10509), X_test: (41, 10509), y_train: (61,), y_test: (41,)\n",
      "Results for Test Sizes: {0.1: {'Decision Tree Accuracy': 0.2727272727272727, 'SVM Accuracy': 0.7272727272727273}, 0.2: {'Decision Tree Accuracy': 0.5714285714285714, 'SVM Accuracy': 0.8095238095238095}, 0.3: {'Decision Tree Accuracy': 0.5806451612903226, 'SVM Accuracy': 0.8709677419354839}, 0.4: {'Decision Tree Accuracy': 0.5121951219512195, 'SVM Accuracy': 0.9024390243902439}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Linear Discriminant Analysis (LDA) and Support Vector Machine (SVM)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "X = Prostate_Tumor_df.iloc[:, 1:]  # All columns except the first (features)\n",
    "y = Prostate_Tumor_df.iloc[:, 0]   # First column (labels)\n",
    "print(f\"Shapes -> X: {X.shape}, y: {y.shape}\")\n",
    "\n",
    "# Ensure X and y are valid for ML\n",
    "if len(X.shape) == 1:\n",
    "    X = X.values.reshape(-1, 1)  # Convert 1D to 2D\n",
    "\n",
    "if len(y.shape) == 1:\n",
    "    y = y.values  # Ensure y is a 1D array\n",
    "\n",
    "# Test size variations\n",
    "test_sizes = [0.1, 0.2, 0.3, 0.4]\n",
    "pca_components = 1\n",
    "results_test_size = {}\n",
    "\n",
    "# Loop over different test sizes\n",
    "for test_size in test_sizes:\n",
    "    # Split data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    print(f\"Train/Test Shapes -> X_train: {X_train.shape}, X_test: {X_test.shape}, y_train: {y_train.shape}, y_test: {y_test.shape}\")\n",
    "    \n",
    "    # Ensure X_train and X_test are 2D arrays\n",
    "    assert len(X_train.shape) == 2, \"X_train should be 2D.\"\n",
    "    assert len(X_test.shape) == 2, \"X_test should be 2D.\"\n",
    "    \n",
    "    # Apply PCA (if needed) or LDA for dimensionality reduction\n",
    "    pca = PCA(n_components=min(pca_components, X_train.shape[1]))  # Ensure n_components doesn't exceed features\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Apply Linear Discriminant Analysis (LDA)\n",
    "    lda = LDA(n_components=min(X_train.shape[1], len(np.unique(y)))-1)  # Ensure n_components <= number of classes - 1\n",
    "    X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "    X_test_lda = lda.transform(X_test)\n",
    "    \n",
    "    # Train and evaluate using Decision Tree\n",
    "    clf_tree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=10, min_samples_split=3, min_samples_leaf=1, max_features=None, random_state=42)\n",
    "    clf_tree.fit(X_train_pca, y_train)\n",
    "    y_pred_tree = clf_tree.predict(X_test_pca)\n",
    "    accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "    \n",
    "    # Train and evaluate using Support Vector Machine (SVM)\n",
    "    clf_svm = SVC(kernel='linear', random_state=42)\n",
    "    clf_svm.fit(X_train_lda, y_train)\n",
    "    y_pred_svm = clf_svm.predict(X_test_lda)\n",
    "    accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "    \n",
    "    results_test_size[test_size] = {'Decision Tree Accuracy': accuracy_tree, 'SVM Accuracy': accuracy_svm}\n",
    "\n",
    "print(\"Results for Test Sizes:\", results_test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df18866a-bb4d-4feb-adbe-9ddd617d62e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> X: \n",
      "(102, 10509), y: (102,)\n",
      "Train/Test Shapes -> X_train: \n",
      "(91, 10509), X_test: (11, 10509), y_train: (91,), y_test: (11,)\n",
      "Train/Test Shapes -> X_train: \n",
      "(81, 10509), X_test: (21, 10509), y_train: (81,), y_test: (21,)\n",
      "Train/Test Shapes -> X_train: \n",
      "(71, 10509), X_test: (31, 10509), y_train: (71,), y_test: (31,)\n",
      "Train/Test Shapes -> X_train: \n",
      "(61, 10509), X_test: (41, 10509), y_train: (61,), y_test: (41,)\n",
      "Results for Test Sizes and SVM Kernels:\n",
      " {'0.1_linear': 0.7272727272727273, '0.1_poly': 0.5454545454545454, '0.1_rbf': 0.7272727272727273, '0.1_sigmoid': 0.7272727272727273, '0.2_linear': 0.8095238095238095, '0.2_poly': 0.6666666666666666, '0.2_rbf': 0.8095238095238095, '0.2_sigmoid': 0.8095238095238095, '0.3_linear': 0.8709677419354839, '0.3_poly': 0.7419354838709677, '0.3_rbf': 0.8709677419354839, '0.3_sigmoid': 0.9032258064516129, '0.4_linear': 0.9024390243902439, '0.4_poly': 0.7804878048780488, '0.4_rbf': 0.9024390243902439, '0.4_sigmoid': 0.926829268292683}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "X = Prostate_Tumor_df.iloc[:, 1:]  # All columns except the first (features)\n",
    "y = Prostate_Tumor_df.iloc[:, 0]   # First column (labels)\n",
    "print(f\"Shapes -> X: \\n{X.shape}, y: {y.shape}\")\n",
    "\n",
    "# Ensure X and y are valid for ML\n",
    "if len(X.shape) == 1:\n",
    "    X = X.values.reshape(-1, 1)  # Convert 1D to 2D\n",
    "\n",
    "if len(y.shape) == 1:\n",
    "    y = y.values  # Ensure y is a 1D array\n",
    "\n",
    "# Test size variations\n",
    "test_sizes = [0.1, 0.2, 0.3, 0.4]\n",
    "pca_components = 1\n",
    "results_test_size = {}\n",
    "\n",
    "# Define the kernels to test\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "# Loop over different test sizes and kernels\n",
    "for test_size in test_sizes:\n",
    "    # Split data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    print(f\"Train/Test Shapes -> X_train: \\n{X_train.shape}, X_test: {X_test.shape}, y_train: {y_train.shape}, y_test: {y_test.shape}\")\n",
    "    \n",
    "    # Ensure X_train and X_test are 2D arrays\n",
    "    assert len(X_train.shape) == 2, \"X_train should be 2D.\"\n",
    "    assert len(X_test.shape) == 2, \"X_test should be 2D.\"\n",
    "    \n",
    "    # Apply PCA (if needed) or LDA for dimensionality reduction\n",
    "    pca = PCA(n_components=min(pca_components, X_train.shape[1]))  # Ensure n_components doesn't exceed features\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Apply Linear Discriminant Analysis (LDA)\n",
    "    lda = LDA(n_components=min(X_train.shape[1], len(np.unique(y)))-1)  # Ensure n_components <= number of classes - 1\n",
    "    X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "    X_test_lda = lda.transform(X_test)\n",
    "    \n",
    "    # Loop over different SVM kernels\n",
    "    for kernel in kernels:\n",
    "        # Train and evaluate using Support Vector Machine (SVM) with different kernels\n",
    "        clf_svm = SVC(kernel=kernel, random_state=42)\n",
    "        clf_svm.fit(X_train_lda, y_train)  # Train with LDA-transformed data\n",
    "        y_pred_svm = clf_svm.predict(X_test_lda)  # Predict with LDA-transformed test data\n",
    "        accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "        \n",
    "        # Store results for each kernel and test size\n",
    "        results_test_size[f\"{test_size}_{kernel}\"] = accuracy_svm\n",
    "\n",
    "# Print the results\n",
    "print(\"Results for Test Sizes and SVM Kernels:\\n\", results_test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7aa4a78d-bc08-44e8-99d9-4501240a4199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA + Decision Tree Results:\n",
      "5-fold: Mean=0.8514, Std=0.0721\n",
      "10-fold: Mean=0.8518, Std=0.1212\n",
      "\n",
      "LDA + SVM (RBF Kernel) Results:\n",
      "5-fold: Mean=0.9010, Std=0.0548\n",
      "10-fold: Mean=0.9118, Std=0.0942\n",
      "\n",
      "LDA + SVM (Linear Kernel) Results:\n",
      "5-fold: Mean=0.9010, Std=0.0548\n",
      "10-fold: Mean=0.9118, Std=0.0942\n",
      "\n",
      "LDA + SVM (Polynomial Kernel) Results:\n",
      "5-fold: Mean=0.9114, Std=0.0724\n",
      "10-fold: Mean=0.8927, Std=0.1124\n"
     ]
    }
   ],
   "source": [
    "# applying 5-fold and 10-fold 10 times \n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Function to perform k-fold cross-validation and repeat it n times using LDA + Classifier\n",
    "def cross_validation_repeat_LDA_with_classifier(X, y, k_folds, n_repeats, lda_components, classifier):\n",
    "    accuracies = []\n",
    "\n",
    "    for _ in range(n_repeats):\n",
    "        # Apply LDA\n",
    "        lda = LDA(n_components=min(lda_components, X.shape[1] - 1))  # Ensure n_components does not exceed (n_features - 1)\n",
    "        X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "        # Perform k-fold cross-validation\n",
    "        kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "        fold_accuracies = cross_val_score(classifier, X_lda, y, cv=kf, scoring='accuracy')\n",
    "        accuracies.extend(fold_accuracies)\n",
    "    \n",
    "    # Calculate mean and standard deviation\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "    return mean_accuracy, std_accuracy\n",
    "\n",
    "\n",
    "# Define classifiers\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "svm_rbf = SVC(kernel='rbf', random_state=42)\n",
    "svm_linear = SVC(kernel='linear', random_state=42)\n",
    "svm_poly = SVC(kernel='poly', random_state=42)\n",
    "\n",
    "# Perform 5-fold and 10-fold cross-validation repeated 10 times for LDA + Decision Tree\n",
    "mean_5_LDA_DT, std_5_LDA_DT = cross_validation_repeat_LDA_with_classifier(X, y, k_folds=5, n_repeats=10, lda_components=1, classifier=decision_tree)\n",
    "mean_10_LDA_DT, std_10_LDA_DT = cross_validation_repeat_LDA_with_classifier(X, y, k_folds=10, n_repeats=10, lda_components=1, classifier=decision_tree)\n",
    "\n",
    "# Perform 5-fold and 10-fold cross-validation repeated 10 times for LDA + SVM (RBF Kernel)\n",
    "mean_5_LDA_SVM_RBF, std_5_LDA_SVM_RBF = cross_validation_repeat_LDA_with_classifier(X, y, k_folds=5, n_repeats=10, lda_components=1, classifier=svm_rbf)\n",
    "mean_10_LDA_SVM_RBF, std_10_LDA_SVM_RBF = cross_validation_repeat_LDA_with_classifier(X, y, k_folds=10, n_repeats=10, lda_components=1, classifier=svm_rbf)\n",
    "\n",
    "# Perform 5-fold and 10-fold cross-validation repeated 10 times for LDA + SVM (Linear Kernel)\n",
    "mean_5_LDA_SVM_Linear, std_5_LDA_SVM_Linear = cross_validation_repeat_LDA_with_classifier(X, y, k_folds=5, n_repeats=10, lda_components=1, classifier=svm_linear)\n",
    "mean_10_LDA_SVM_Linear, std_10_LDA_SVM_Linear = cross_validation_repeat_LDA_with_classifier(X, y, k_folds=10, n_repeats=10, lda_components=1, classifier=svm_linear)\n",
    "\n",
    "# Perform 5-fold and 10-fold cross-validation repeated 10 times for LDA + SVM (Polynomial Kernel)\n",
    "mean_5_LDA_SVM_Poly, std_5_LDA_SVM_Poly = cross_validation_repeat_LDA_with_classifier(X, y, k_folds=5, n_repeats=10, lda_components=1, classifier=svm_poly)\n",
    "mean_10_LDA_SVM_Poly, std_10_LDA_SVM_Poly = cross_validation_repeat_LDA_with_classifier(X, y, k_folds=10, n_repeats=10, lda_components=1, classifier=svm_poly)\n",
    "\n",
    "# Print results\n",
    "print(\"LDA + Decision Tree Results:\")\n",
    "print(f\"5-fold: Mean={mean_5_LDA_DT:.4f}, Std={std_5_LDA_DT:.4f}\")\n",
    "print(f\"10-fold: Mean={mean_10_LDA_DT:.4f}, Std={std_10_LDA_DT:.4f}\")\n",
    "\n",
    "print(\"\\nLDA + SVM (RBF Kernel) Results:\")\n",
    "print(f\"5-fold: Mean={mean_5_LDA_SVM_RBF:.4f}, Std={std_5_LDA_SVM_RBF:.4f}\")\n",
    "print(f\"10-fold: Mean={mean_10_LDA_SVM_RBF:.4f}, Std={std_10_LDA_SVM_RBF:.4f}\")\n",
    "\n",
    "print(\"\\nLDA + SVM (Linear Kernel) Results:\")\n",
    "print(f\"5-fold: Mean={mean_5_LDA_SVM_Linear:.4f}, Std={std_5_LDA_SVM_Linear:.4f}\")\n",
    "print(f\"10-fold: Mean={mean_10_LDA_SVM_Linear:.4f}, Std={std_10_LDA_SVM_Linear:.4f}\")\n",
    "\n",
    "print(\"\\nLDA + SVM (Polynomial Kernel) Results:\")\n",
    "print(f\"5-fold: Mean={mean_5_LDA_SVM_Poly:.4f}, Std={std_5_LDA_SVM_Poly:.4f}\")\n",
    "print(f\"10-fold: Mean={mean_10_LDA_SVM_Poly:.4f}, Std={std_10_LDA_SVM_Poly:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e198e-7494-437f-8eaa-eb215d7c7520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
